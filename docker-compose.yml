version: "3.9"

x-env: &default-env
  MINIO_ROOT_USER: minio
  MINIO_ROOT_PASSWORD: minio123
  CLICKHOUSE_USER: admin
  CLICKHOUSE_PASSWORD: clickhouse

networks:
  de_net:
    driver: bridge

volumes:
  postgres_airflow_data:
  postgres_app_data:
  postgres_superset_data:
  clickhouse_data:
  minio_data:
  superset_home:
  notebooks:

services:
  # ---------- Postgres for app ----------
  postgres-src:
    image: postgres:14
    container_name: postgres-src
    command: postgres -c wal_level=logical -c max_replication_slots=5 -c max_wal_senders=5
    environment:
      - POSTGRES_USER=postgres
      - POSTGRES_PASSWORD=postgres
      - POSTGRES_DB=mydb
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres -d mydb"]
      interval: 5s
      timeout: 5s
      retries: 5
    volumes:
      - postgres_app_data:/var/lib/postgresql/data
    ports:
      - "5433:5432"
    networks: [de_net]

  # ---------- Zookeeper ----------
  zookeeper:
    image: zookeeper:3.8.2
    container_name: zookeeper
    environment:
      - ALLOW_ANONYMOUS_LOGIN=yes
    ports:
      - "2181:2181"
    networks: [de_net]

  # ---------- Kafka ----------
  kafka:
    image: confluentinc/cp-kafka:7.5.1
    container_name: kafka
    depends_on: [zookeeper]
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092,PLAINTEXT_HOST://localhost:29092
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: 'true'
      KAFKA_DELETE_TOPIC_ENABLE: 'true'
    ports:
      - "9092:9092"
      - "29092:29092"
    networks: [de_net]

  # ---------- Debezium Kafka Connect ----------
  debezium:
    image: debezium/connect:2.7.0.Final
    container_name: debezium
    depends_on: [kafka, zookeeper]
    environment:
      - BOOTSTRAP_SERVERS=kafka:9092
      - GROUP_ID=1
      - CONFIG_STORAGE_TOPIC=debezium_config
      - OFFSET_STORAGE_TOPIC=debezium_offsets
      - STATUS_STORAGE_TOPIC=debezium_status
      - KEY_CONVERTER=org.apache.kafka.connect.json.JsonConverter
      - VALUE_CONVERTER=org.apache.kafka.connect.json.JsonConverter
      - ENABLE_DEBEZIUM_SCRIPTING=true
    ports:
      - "8083:8083"
    networks: [de_net]

  # ---------- Kafka UI ----------
  kafka-ui:
    image: provectuslabs/kafka-ui:latest
    container_name: kafka-ui
    depends_on:
      - kafka
      - debezium
    ports:
      - "8082:8080"
    environment:
      KAFKA_CLUSTERS_0_NAME: local
      KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS: kafka:9092
      KAFKA_CLUSTERS_0_ZOOKEEPER: zookeeper:2181
      KAFKA_CLUSTERS_0_KAFKACONNECT_0_NAME: connect
      KAFKA_CLUSTERS_0_KAFKACONNECT_0_ADDRESS: http://debezium:8083
    networks:
      - de_net

  # ---------- MinIO ----------
  minio:
    image: minio/minio:latest
    container_name: minio
    command: server /data --console-address ":9001"
    environment:
      MINIO_ROOT_USER: ${MINIO_ROOT_USER:-minio}
      MINIO_ROOT_PASSWORD: ${MINIO_ROOT_PASSWORD:-minio123}
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9000/minio/health/live"]
      interval: 30s
      timeout: 20s
      retries: 3
    ports:
      - "9002:9000"
      - "9001:9001"
    volumes:
      - minio_data:/data
    networks: [de_net]
    
  # ---------- MinIO init (bucket + folders) ----------
  minio-init:
    image: minio/mc:latest
    depends_on:
      - minio
    entrypoint: >
      /bin/sh -c "
        sleep 5 &&
        mc alias set local http://minio:9000 minio minio123 &&
        mc mb local/bucket || true &&
        mc mb local/bucket/batch_output || true &&
        mc mb local/bucket/kafka_output || true &&
        exit 0
      "
    networks: [de_net]

  # ---------- ClickHouse ----------
  clickhouse:
    image: clickhouse/clickhouse-server:23.10
    container_name: clickhouse
    ports:
      - "8123:8123"  # HTTP
      - "9000:9000"  # Native
    volumes:
      - clickhouse_data:/var/lib/clickhouse
    environment:
      - CLICKHOUSE_DB=default
      - CLICKHOUSE_USER=default
      - CLICKHOUSE_PASSWORD=
      - CLICKHOUSE_DEFAULT_ACCESS_MANAGEMENT=1
      - CLICKHOUSE_ALLOW_SPARK=1
      - CLICKHOUSE_NETWORK_COMPRESSION=1
    networks:
      - de_net

  # ------------ Airflow -------------

  # ---------- Postgres for Airflow ----------
  postgres-airflow:
    image: postgres:14
    container_name: postgres-airflow
    environment:
      - POSTGRES_USER=airflow
      - POSTGRES_PASSWORD=airflow
      - POSTGRES_DB=airflow
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U airflow -d airflow"]
      interval: 5s
      timeout: 5s
      retries: 5
    volumes:
      - postgres_airflow_data:/var/lib/postgresql/data
    networks: [de_net]

  # ---------- Airflow Initialization ----------
  airflow-init:
    build:
      context: .        # <- использует твой Dockerfile
      dockerfile: Dockerfile.airflow
    container_name: airflow-init
    depends_on:
      - postgres-airflow
    entrypoint: >
      bash -c "airflow db upgrade &&
               airflow users create --username admin --password admin --firstname Admin --lastname User --role Admin --email admin@example.com || true"
    environment:
      - AIRFLOW__CORE__EXECUTOR=LocalExecutor
      - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql+psycopg2://airflow:airflow@postgres-airflow:5432/airflow
      - AIRFLOW__CORE__FERNET_KEY=please_change_me
      - AIRFLOW__CORE__LOAD_EXAMPLES=False
    networks: [de_net]

  # ---------- Airflow Webserver ----------
  airflow-webserver:
    build:
      context: .
      dockerfile: Dockerfile.airflow
    container_name: airflow-webserver
    depends_on:
      - airflow-init
    command: webserver
    environment:
      - AIRFLOW__CORE__EXECUTOR=LocalExecutor
      - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql+psycopg2://airflow:airflow@postgres-airflow:5432/airflow
      - AIRFLOW__WEBSERVER__RBAC=True
      - AIRFLOW__CORE__FERNET_KEY=please_change_me
      - AIRFLOW__CORE__LOAD_EXAMPLES=False
      - AIRFLOW_CONN_S3_CONN=s3://minio:minio123@minio:9000/
    volumes:
      - ./dags:/opt/airflow/dags
      - ./plugins:/opt/airflow/plugins
      - ./logs:/opt/airflow/logs
    ports:
      - "8080:8080"
    networks: [de_net]

  # ---------- Airflow Scheduler ----------
  airflow-scheduler:
    build:
      context: .
      dockerfile: Dockerfile.airflow
    container_name: airflow-scheduler
    depends_on:
      - airflow-init
    command: scheduler
    environment:
      - AIRFLOW__CORE__EXECUTOR=LocalExecutor
      - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql+psycopg2://airflow:airflow@postgres-airflow:5432/airflow
      - AIRFLOW__CORE__FERNET_KEY=please_change_me
      - AIRFLOW__CORE__LOAD_EXAMPLES=False
      - AIRFLOW_CONN_S3_CONN=s3://minio:minio123@minio:9000/
    volumes:
      - ./dags:/opt/airflow/dags
      - ./plugins:/opt/airflow/plugins
      - ./logs:/opt/airflow/logs
    networks: [de_net]


  # ---------- Superset ----------
  superset:
    build:
      context: .
      dockerfile: Dockerfile.superset
    container_name: superset
    ports:
      - "8088:8088"
    environment:
      SUPERSET_ENV: development
      SUPERSET_LOAD_EXAMPLES: "no"
      SUPERSET_SECRET_KEY: supersecret
    depends_on:
      - clickhouse
    networks:
      - de_net
    volumes:
      - superset_home:/app/superset_home    

  # ---------- DBT ----------
  dbt:
    container_name: dbt
    build:
      context: .
      dockerfile: Dockerfile.dbt
    working_dir: /usr/app
    command: ["sleep", "infinity"]
    volumes:
      - ./dbt:/usr/app
      - ./dbt/profiles.yml:/root/.dbt/profiles.yml
    networks:
     - de_net

  # --------- Spark ----------
  spark:
    image: apache/spark:3.5.1
    container_name: spark
    ports:
      - "7077:7077"  # Spark
      - "8081:8080"  # Spark UI
    volumes:
      - ./scripts:/home/jovyan/scripts
      - ./spark/jars:/opt/spark/jars
    environment:
      - SPARK_MODE=master
      - MINIO_ENDPOINT=http://minio:9000
      - MINIO_ACCESS_KEY=minio
      - MINIO_SECRET_KEY=minio123
    networks: [de_net]

  # --------- Jupyter ----------
  jupyter:
    image: jupyter/pyspark-notebook:latest
    container_name: jupyter
    ports:
      - "8889:8888"
    volumes:
      - ./notebooks:/home/jovyan/notebooks
      - ./scripts:/home/jovyan/scripts
      - ./spark/jars:/opt/spark/jars
    environment:
      - SPARK_MASTER=spark://spark:7077
      - MINIO_ENDPOINT=http://minio:9000
      - MINIO_ACCESS_KEY=minio
      - MINIO_SECRET_KEY=minio123
      - JUPYTER_TOKEN=admin
    networks: [de_net]
    depends_on:
      - spark